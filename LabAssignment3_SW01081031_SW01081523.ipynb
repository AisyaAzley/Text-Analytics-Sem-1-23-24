{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6c0ee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nur\n",
      "[nltk_data]     Adilah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Nur\n",
      "[nltk_data]     Adilah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nur\n",
      "[nltk_data]     Adilah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# For topic modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "# Download NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7917055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>Secrecy in Clipper Chip\\n\\nThe serial number o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>Hi !\\n\\nI am interested in the source of FEAL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>The actual algorithm is classified, however, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>\\n\\tThis appears to be generic calling upon th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>\\nProbably keep quiet and take it, lest they g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      I was wondering if anyone out there could enli...\n",
       "1      I recently posted an article asking what kind ...\n",
       "2      \\nIt depends on your priorities.  A lot of peo...\n",
       "3      an excellent automatic can be found in the sub...\n",
       "4      : Ford and his automobile.  I need information...\n",
       "...                                                  ...\n",
       "11309  Secrecy in Clipper Chip\\n\\nThe serial number o...\n",
       "11310  Hi !\\n\\nI am interested in the source of FEAL ...\n",
       "11311  The actual algorithm is classified, however, t...\n",
       "11312  \\n\\tThis appears to be generic calling upon th...\n",
       "11313  \\nProbably keep quiet and take it, lest they g...\n",
       "\n",
       "[11314 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data (use only the ‘text’ column)\n",
    "data = pd.read_csv('news_dataset.csv', usecols=['text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2dbaa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11096, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove null values\n",
    "data.dropna(subset=['text'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00d6741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize necessary tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess(text):\n",
    "    # Remove special characters, digits, and single letters, then make lowercase\n",
    "    text = re.sub(r'\\W', ' ', str(text))  # Remove special characters\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Remove single letters\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)  # Remove single letters from start\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)  # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)  # Remove all single characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Remove any remaining tokens of only one character\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "data['processed_text'] = data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "712dbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and corpus for the LDA model\n",
    "id2word = corpora.Dictionary(data['processed_text'])\n",
    "texts = data['processed_text']\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "179777d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus,\n",
    "                                   id2word=id2word,\n",
    "                                   num_topics=4,\n",
    "                                   passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1eb0b3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0      I was wondering if anyone out there could enli...      0\n",
      "1      I recently posted an article asking what kind ...      0\n",
      "2      \\nIt depends on your priorities.  A lot of peo...      0\n",
      "3      an excellent automatic can be found in the sub...      0\n",
      "4      : Ford and his automobile.  I need information...      0\n",
      "...                                                  ...    ...\n",
      "11309  Secrecy in Clipper Chip\\n\\nThe serial number o...      0\n",
      "11310  Hi !\\n\\nI am interested in the source of FEAL ...      0\n",
      "11311  The actual algorithm is classified, however, t...      0\n",
      "11312  \\n\\tThis appears to be generic calling upon th...      0\n",
      "11313  \\nProbably keep quiet and take it, lest they g...      3\n",
      "\n",
      "[11096 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign dominant topic to each document\n",
    "article_labels = []\n",
    "\n",
    "for doc in texts:\n",
    "    # Convert document to bag-of-words representation\n",
    "    bow = id2word.doc2bow(doc)\n",
    "    # Get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # Determine topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    # Append to the list\n",
    "    article_labels.append(dominant_topic)\n",
    "\n",
    "# Create DataFrame\n",
    "df_result = pd.DataFrame({\"Article\": data['text'], \"Topic\": article_labels})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df_result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c672a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for Topic #0:\n",
      "['use', 'key', 'would', 'one', 'encrypt', 'system', 'get', 'like', 'work', 'chip']\n",
      "\n",
      "Top terms for Topic #1:\n",
      "['ax', 'max', 'gv', 'bf', 'pl', 'di', 'bh', 'cx', 'tm', 'bhj']\n",
      "\n",
      "Top terms for Topic #2:\n",
      "['edu', 'file', 'db', 'window', 'anonym', 'use', 'program', 'com', 'mail', 'ftp']\n",
      "\n",
      "Top terms for Topic #3:\n",
      "['peopl', 'one', 'would', 'say', 'think', 'go', 'like', 'know', 'time', 'year']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms for each topic\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    print(f\"Top terms for Topic #{topic_id}:\")\n",
    "    top_terms = lda_model.show_topic(topic_id, topn=10)\n",
    "    print([term[0] for term in top_terms])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0088bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.7171447255423457\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the LDA model using Coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acd1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Student name and id\n",
    "# Aisya Batrisyia BInti Azley SW01081523\n",
    "# Nur Adilah Binti Zainal Abidin SW01081031\n",
    "\n",
    "# The coherence score (0.717) indicates that the level of semantic similarity and meaningfulness\n",
    "# among the words thus the topics are well-formed and interpretable thus providing coherent and distinct \n",
    "# themes that are useful in understanding the structure of the text data. Hence, the model is a well-performing one. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d785170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
